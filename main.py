import streamlit as st
import nltk
import heapq
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
from collections import Counter
import matplotlib.pyplot as plt
from PIL import Image
from datetime import datetime
import csv
import os

# ----------------- CONFIGURATION NLTK -----------------
def safe_nltk_download(resource):
    """T√©l√©charge les ressources NLTK de mani√®re s√©curis√©e"""
    try:
        nltk.data.find(resource)
    except LookupError:
        try:
            # Essaie d'abord avec le nom complet
            nltk.download(resource.split("/")[-1])
        except:
            # Si √ßa √©choue, essaie avec des alternatives
            if "punkt" in resource:
                try:
                    nltk.download("punkt_tab")
                except:
                    nltk.download("punkt")
            elif "stopwords" in resource:
                nltk.download("stopwords")

# T√©l√©charger les ressources n√©cessaires avec gestion d'erreur am√©lior√©e
@st.cache_resource
def init_nltk():
    """Initialise NLTK avec cache pour √©viter les t√©l√©chargements r√©p√©t√©s"""
    try:
        safe_nltk_download("tokenizers/punkt")
        safe_nltk_download("tokenizers/punkt_tab")
        safe_nltk_download("corpora/stopwords")
    except Exception as e:
        st.error(f"Erreur lors du t√©l√©chargement des ressources NLTK: {e}")
        # T√©l√©chargement direct en cas d'√©chec
        try:
            nltk.download("punkt_tab", quiet=True)
            nltk.download("punkt", quiet=True)
            nltk.download("stopwords", quiet=True)
        except:
            pass

# Initialiser NLTK
init_nltk()

# ----------------- FONCTIONS -----------------
def enregistrer_texte_utilise(action, texte, resultat=""):
    """Enregistre l'historique des actions dans un fichier CSV"""
    try:
        now = datetime.now().strftime("%d-%m-%Y %H:%M")
        with open("historique.csv", mode='a', newline='', encoding='utf-8') as historique:
            writer = csv.writer(historique)
            writer.writerow([now, action, texte[:100], resultat[:100]])
    except Exception as e:
        st.warning(f"Impossible d'enregistrer l'historique: {e}")

def resumer_texte(texte, nb_phrases=2):
    """R√©sume un texte en s√©lectionnant les phrases les plus importantes"""
    try:
        # Tokenisation des phrases avec gestion d'erreur
        try:
            phrases = sent_tokenize(texte, language='french')
        except:
            # Fallback: utilise un tokenizer plus simple si NLTK √©choue
            phrases = texte.split('.')
            phrases = [p.strip() + '.' for p in phrases if p.strip()]
        
        if len(phrases) <= nb_phrases:
            return phrases
        
        # Tokenisation des mots
        try:
            mots = word_tokenize(texte.lower())
        except:
            # Fallback simple
            mots = texte.lower().split()
        
        # R√©cup√©ration des stopwords
        try:
            stop_words = set(stopwords.words("french"))
        except:
            # Fallback avec des stopwords basiques en fran√ßais
            stop_words = set(['le', 'de', 'et', '√†', 'un', 'il', '√™tre', 'et', 'en', 'avoir', 'que', 'pour', 'dans', 'ce', 'son', 'une', 'sur', 'avec', 'ne', 'se', 'pas', 'tout', 'plus', 'par', 'grand', 'en', 'on', 'aller', 'pouvoir', 'aussi', 'du', 'au', 'si', 'te', 'mais', 'ou', 'bien', 'non', 'comme', 'faire', 'sa', 'voir', 'lui', 'nous', 'je', 'me', 'ma', 'tr√®s'])
        
        # Filtrage des mots utiles
        mots_utiles = [mot for mot in mots if mot.isalnum() and mot not in stop_words and len(mot) > 2]
        
        if not mots_utiles:
            return phrases[:nb_phrases]
        
        # Calcul des fr√©quences
        frequences = Counter(mots_utiles)
        max_freq = max(frequences.values())
        
        # Normalisation des fr√©quences
        for mot in frequences:
            frequences[mot] /= max_freq

        # Calcul du score de chaque phrase
        scores_phrases = {}
        for phrase in phrases:
            score = 0
            try:
                mots_phrase = word_tokenize(phrase.lower())
            except:
                mots_phrase = phrase.lower().split()
            
            for mot in mots_phrase:
                if mot in frequences and len(phrase.split(" ")) < 30:
                    score += frequences[mot]
            
            if score > 0:
                scores_phrases[phrase] = score
        
        if not scores_phrases:
            return phrases[:nb_phrases]
        
        # Retour des meilleures phrases
        return heapq.nlargest(nb_phrases, scores_phrases, key=scores_phrases.get)
    
    except Exception as e:
        st.error(f"Erreur lors du r√©sum√©: {e}")
        return texte.split('.')[:nb_phrases]

def analyser_frequences(texte):
    """Analyse la fr√©quence des mots dans un texte"""
    try:
        try:
            mots = word_tokenize(texte.lower())
        except:
            mots = texte.lower().split()
        
        try:
            stop_words = set(stopwords.words("french"))
        except:
            stop_words = set(['le', 'de', 'et', '√†', 'un', 'il', '√™tre', 'et', 'en', 'avoir', 'que', 'pour', 'dans', 'ce', 'son', 'une', 'sur', 'avec', 'ne', 'se', 'pas', 'tout', 'plus', 'par', 'grand', 'en', 'on', 'aller', 'pouvoir', 'aussi', 'du', 'au', 'si', 'te', 'mais', 'ou', 'bien', 'non', 'comme', 'faire', 'sa', 'voir', 'lui', 'nous', 'je', 'me', 'ma', 'tr√®s'])
        
        mots_utiles = [mot for mot in mots if mot.isalnum() and mot not in stop_words and len(mot) > 2]
        return Counter(mots_utiles).most_common(10)
    except Exception as e:
        st.error(f"Erreur lors de l'analyse: {e}")
        return []

def chatbot_local(message):
    """Chatbot simple avec r√©ponses pr√©d√©finies"""
    message = message.lower()
    if "bonjour" in message or "salut" in message:
        return "Bonjour ! Je suis BuildBot. En quoi puis-je vous aider ?"
    elif "aide" in message or "quoi" in message or "comment" in message:
        return "Je peux r√©sumer du texte, analyser les mots fr√©quents ou r√©pondre √† des questions simples. Utilisez le menu √† gauche pour choisir une fonction."
    elif "merci" in message:
        return "Avec plaisir ! üòä"
    elif "au revoir" in message or "bye" in message:
        return "Au revoir ! √Ä bient√¥t ! üëã"
    elif "qui es-tu" in message or "qui √™tes-vous" in message:
        return "Je suis BuildBot, un assistant IA pour analyser et r√©sumer du texte."
    else:
        return "Je ne comprends pas encore cette question. Essayez de me demander de l'aide ou utilisez les fonctions du menu."

# ----------------- INTERFACE STREAMLIT -----------------
def main():
    # Configuration de la page
    st.set_page_config(
        page_title="Build-Main AI Tools", 
        layout="centered",
        initial_sidebar_state="expanded"
    )
    
    # Sidebar
    st.sidebar.title("üß† Build-Main AI Tools")
    
    # Tentative de chargement du logo
    try:
        logo = Image.open("logo.png")
        st.sidebar.image(logo, width=200)
    except:
        st.sidebar.write("ü§ñ Logo non trouv√©")

    # Titre principal
    st.markdown(
        "<h1 style='text-align: center; color: #5A5A5A;'>ü§ñ Build-Main AI Tools</h1>", 
        unsafe_allow_html=True
    )
    
    # Menu de choix
    choix = st.sidebar.radio(
        "Choisissez une fonction :", 
        ["R√©sum√©", "Chatbot", "Analyse de mots", "Importer un fichier texte"]
    )

    texte = ""

    # Interface selon le choix
    if choix == "Importer un fichier texte":
        st.title("üìÅ Importation de fichier")
        fichier = st.file_uploader("Chargez un fichier .txt", type=["txt"])
        if fichier:
            try:
                texte = fichier.read().decode("utf-8")
                st.success("Fichier charg√© avec succ√®s !")
                st.text_area("Texte import√© :", texte, height=200)
                
                # Options suppl√©mentaires apr√®s import
                st.subheader("Actions disponibles:")
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("R√©sumer ce texte"):
                        st.session_state.texte_importe = texte
                        st.session_state.page_active = "R√©sum√©"
                        st.rerun()
                
                with col2:
                    if st.button("Analyser les mots"):
                        st.session_state.texte_importe = texte
                        st.session_state.page_active = "Analyse de mots"
                        st.rerun()
                        
            except Exception as e:
                st.error(f"Erreur lors du chargement du fichier: {e}")

    elif choix == "R√©sum√©":
        st.title("üìù R√©sum√© automatique")
        
        # V√©rifier s'il y a du texte import√©
        if hasattr(st.session_state, 'texte_importe') and hasattr(st.session_state, 'page_active') and st.session_state.page_active == "R√©sum√©":
            texte = st.text_area("Texte √† r√©sumer :", st.session_state.texte_importe, height=200)
            # Nettoyer la session
            del st.session_state.texte_importe
            del st.session_state.page_active
        else:
            texte = st.text_area("Entrez le texte √† r√©sumer :", height=200)
        
        nb = st.slider("Nombre de phrases dans le r√©sum√©", 1, 5, 2)
        
        if st.button("G√©n√©rer le r√©sum√©") and texte.strip():
            with st.spinner("G√©n√©ration du r√©sum√©..."):
                lignes = resumer_texte(texte, nb)
                
                if lignes:
                    st.subheader("üìã R√©sum√© g√©n√©r√©:")
                    for i, ligne in enumerate(lignes, 1):
                        st.write(f"{i}. {ligne}")
                    
                    # Enregistrement
                    enregistrer_texte_utilise("R√©sum√©", texte, " ".join(lignes))
                    st.success("R√©sum√© g√©n√©r√© avec succ√®s !")
                else:
                    st.error("Impossible de g√©n√©rer un r√©sum√© pour ce texte.")
        elif st.button("G√©n√©rer le r√©sum√©") and not texte.strip():
            st.warning("Veuillez saisir du texte √† r√©sumer.")

    elif choix == "Chatbot":
        st.title("üí¨ ChatBot (local)")
        
        # Historique des conversations
        if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []
        
        # Affichage de l'historique
        for message in st.session_state.chat_history:
            if message['type'] == 'user':
                st.write(f"üë§ **Vous:** {message['content']}")
            else:
                st.write(f"ü§ñ **BuildBot:** {message['content']}")
        
        # Input pour nouvelle question
        question = st.text_input("Posez une question √† BuildBot :", key="chat_input")
        
        if st.button("Envoyer") and question.strip():
            # Ajouter la question √† l'historique
            st.session_state.chat_history.append({'type': 'user', 'content': question})
            
            # G√©n√©rer et ajouter la r√©ponse
            reponse = chatbot_local(question)
            st.session_state.chat_history.append({'type': 'bot', 'content': reponse})
            
            # Rafra√Æchir la page pour afficher la conversation
            st.rerun()
        
        # Bouton pour effacer l'historique
        if st.button("Effacer l'historique"):
            st.session_state.chat_history = []
            st.rerun()

    elif choix == "Analyse de mots":
        st.title("üìä Analyse des mots les plus fr√©quents")
        
        # V√©rifier s'il y a du texte import√©
        if hasattr(st.session_state, 'texte_importe') and hasattr(st.session_state, 'page_active') and st.session_state.page_active == "Analyse de mots":
            texte = st.text_area("Texte √† analyser :", st.session_state.texte_importe, height=200)
            # Nettoyer la session
            del st.session_state.texte_importe
            del st.session_state.page_active
        else:
            texte = st.text_area("Entrez un texte √† analyser :", height=200)
        
        if texte.strip():
            with st.spinner("Analyse en cours..."):
                freqs = analyser_frequences(texte)
                
                if freqs:
                    st.subheader("üìà Graphique des mots les plus fr√©quents")
                    mots, valeurs = zip(*freqs)
                    
                    # Cr√©er un dictionnaire pour le graphique
                    data_chart = {mot: val for mot, val in zip(mots, valeurs)}
                    st.bar_chart(data_chart)
                    
                    st.subheader("üìù Top 10 des mots les plus fr√©quents")
                    for i, (mot, freq) in enumerate(freqs, 1):
                        st.write(f"{i}. **{mot}** : {freq} occurrences")
                    
                    # Statistiques suppl√©mentaires
                    st.subheader("üìä Statistiques du texte")
                    nb_mots_total = len(texte.split())
                    nb_mots_uniques = len(set(texte.lower().split()))
                    nb_caracteres = len(texte)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Mots total", nb_mots_total)
                    with col2:
                        st.metric("Mots uniques", nb_mots_uniques)
                    with col3:
                        st.metric("Caract√®res", nb_caracteres)
                    
                    enregistrer_texte_utilise("Analyse", texte, str(freqs[:3]))
                else:
                    st.warning("Aucun mot significatif trouv√© dans le texte.")

    # Footer
    st.sidebar.markdown("---")
    st.sidebar.markdown("**Build-Main AI Tools** v2.0")
    st.sidebar.markdown("D√©velopp√© avec ‚ù§Ô∏è et Streamlit")

if __name__ == "__main__":
    main()